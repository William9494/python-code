{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Essentials â€” Practical Notebook\n",
        "\n",
        "Generated: 2025-09-02 02:01 UTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, seaborn as sns, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, confusion_matrix, mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from joblib import dump\n",
        "sns.set_theme(context='notebook', style='whitegrid', palette='deep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate synthetic dataset (toggle task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification, make_regression\n",
        "TASK='classification'  # or 'regression'\n",
        "if TASK=='classification':\n",
        "    X, y = make_classification(n_samples=1500, n_features=10, n_informative=5, random_state=7)\n",
        "    cols=[f'f{i}' for i in range(10)]; df = pd.DataFrame(X, columns=cols); df['label']=y; df['cat']=np.random.default_rng(7).choice(['A','B','C'], size=len(df)); TARGET='label'\n",
        "else:\n",
        "    X, y = make_regression(n_samples=1500, n_features=12, n_informative=6, noise=12.0, random_state=7)\n",
        "    cols=[f'f{i}' for i in range(12)]; df = pd.DataFrame(X, columns=cols); df['target']=y; df['cat']=np.random.default_rng(7).choice(['A','B','C'], size=len(df)); TARGET='target'\n",
        "# Or load your CSV: df = pd.read_csv('your.csv'); TARGET='your_target'\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing + model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=[TARGET]); y = df[TARGET]\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "num_pipe = Pipeline([('impute', SimpleImputer(strategy='median')), ('scale', StandardScaler())])\n",
        "cat_pipe = Pipeline([('impute', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "pre = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)])\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y if TASK=='classification' else None)\n",
        "model = RandomForestClassifier(n_estimators=300, random_state=7) if TASK=='classification' else RandomForestRegressor(n_estimators=300, random_state=7)\n",
        "pipe = Pipeline([('pre', pre), ('model', model)])\n",
        "pipe.fit(Xtr, ytr)\n",
        "yp = pipe.predict(Xte)\n",
        "\n",
        "if TASK=='classification':\n",
        "    yproba = pipe.predict_proba(Xte) if hasattr(pipe['model'], 'predict_proba') else None\n",
        "    metrics = {'accuracy': accuracy_score(yte, yp), 'balanced_accuracy': balanced_accuracy_score(yte, yp), 'f1_weighted': f1_score(yte, yp, average='weighted')}\n",
        "    if yproba is not None:\n",
        "        try: metrics['roc_auc_ovr'] = roc_auc_score(yte, yproba, multi_class='ovr')\n",
        "        except Exception: pass\n",
        "    print(metrics); print('Confusion matrix:\n",
        "', confusion_matrix(yte, yp))\n",
        "else:\n",
        "    print({'MAE': mean_absolute_error(yte, yp), 'RMSE': mean_squared_error(yte, yp, squared=False), 'R2': r2_score(yte, yp)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-validation & tuning (quick)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=7) if TASK=='classification' else KFold(n_splits=5, shuffle=True, random_state=7)\n",
        "scoring = 'f1_weighted' if TASK=='classification' else 'neg_root_mean_squared_error'\n",
        "scores = cross_val_score(pipe, X, y, cv=cv, scoring=scoring)\n",
        "print('CV', scoring, '->', scores.mean(), '+/-', scores.std())\n",
        "\n",
        "param_grid = {'model__n_estimators':[200,400], 'model__max_depth':[None,10,20]}\n",
        "search = GridSearchCV(pipe, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=-1)\n",
        "search.fit(X, y)\n",
        "print('Best:', search.best_params_, 'score:', search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Permutation importance & save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = permutation_importance(pipe, Xte, yte, n_repeats=5, random_state=7)\n",
        "imp = pd.DataFrame({'feature': pipe['pre'].get_feature_names_out(), 'importance': r.importances_mean})\n",
        "print(imp.sort_values('importance', ascending=False).head(20))\n",
        "\n",
        "dump(pipe, 'model_quickstart.pkl'); 'Saved model_quickstart.pkl'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}